{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymongo\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News\n",
    "Collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_url = 'https://mars.nasa.gov/news/'\n",
    "browser.visit(nasa_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Robotic Toolkit Added to NASA's Mars 2020 Rover\n",
      "Teaser: The bit carousel, which lies at the heart of the rover's Sample Caching System, is now aboard NASA's newest rover. \n"
     ]
    }
   ],
   "source": [
    "# HTML Object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve the latest news_title and news_paragraph\n",
    "news_title = soup.find('div', class_='content_title').find('a').text\n",
    "news_p = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "# Display article tital and teaser text \n",
    "print(f'Article: {news_title}')\n",
    "print(f'Teaser: {news_p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "Use splinter to find the image url for the current Featured Mars Image. \n",
    "Assign the url string to a variable called `featured_image_url`.\n",
    "Make sure to find the image url to the full size `.jpg` image\n",
    "Make sure to save a complete url string for this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Space Images through splinter module\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Featured Image URL: https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA00069-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# JPL main Website Ur 'https://www.jpl.nasa.gov'\n",
    "\n",
    "# HTML Object \n",
    "html_image = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "image_soup = BeautifulSoup(html_image, 'html.parser')\n",
    "\n",
    "# Retrieve background-image url from style tag \n",
    "featured_image_url = image_soup.find('article')['style'].replace('background-image: url(','').replace(');', '')[1:-1]\n",
    "\n",
    "print(f'Featured Image URL: https://www.jpl.nasa.gov{featured_image_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather \n",
    "Scrape the latest Mars weather tweets. Save the tweet text for the weather report as a variable called `mars_weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit Mars Weather Twitter through splinter module\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Tweet about Mars Weather: \"InSight sol 261 (2019-08-21) low -102.4ºC (-152.4ºF) high -26.6ºC (-15.8ºF)\n",
      "winds from the SSE at 4.9 m/s (11.0 mph) gusting to 16.0 m/s (35.8 mph)\n",
      "pressure at 7.70 hPapic.twitter.com/MhPPOHJg3m\"\n"
     ]
    }
   ],
   "source": [
    "# HTML Object \n",
    "weather_html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "tweet_soup = BeautifulSoup(weather_html, 'html.parser')\n",
    "\n",
    "# Find all elements that contain tweets\n",
    "weather_tweet = tweet_soup.find('p', class_='TweetTextSize TweetTextSize--normal js-tweet-text tweet-text').text\n",
    "\n",
    "print(f'Latest Tweet about Mars Weather: \"{weather_tweet}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "Use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc. Use Pandas to convert the data to a HTML table string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars_Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fact_Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diameter:</th>\n",
       "      <td>6,779 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from Sun:</th>\n",
       "      <td>227,943,824 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Length of Year:</th>\n",
       "      <td>687 Earth days</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Mars_Value\n",
       "Fact_Category                      \n",
       "Diameter:                  6,779 km\n",
       "Mass:               6.39 × 10^23 kg\n",
       "Moons:                            2\n",
       "Distance from Sun:   227,943,824 km\n",
       "Length of Year:      687 Earth days"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the table of Mars facts\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# Use Panda's `read_html` to parse the url\n",
    "tables = pd.read_html(facts_url)\n",
    "\n",
    "# Create datarame and columns \n",
    "df = tables[0]\n",
    "\n",
    "# Rename Columns\n",
    "df.columns = ['Fact_Category', 'Mars_Value', 'Earth_Value']\n",
    "\n",
    "# Remove Earth_Values\n",
    "facts_df = df[['Fact_Category', 'Mars_Value',]]\n",
    "\n",
    "# Set Facts_Category as Index\n",
    "facts_df.set_index('Fact_Category', inplace=True)\n",
    "\n",
    "# Print Dataframe\n",
    "facts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars_Value</th>\\n    </tr>\\n    <tr>\\n      <th>Fact_Category</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Dataframe to HTML\n",
    "facts_df.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "Obtain high resolution images for each of Mar's hemispheres. You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image\n",
    "* Save both the image url string for the full resolution hemisphere image\n",
    "* Save the Hemisphere title containing the hemisphere name\n",
    "* Use a Python dictionary to store the data using the keys `img_url` and `title`. \n",
    "* Append the dictionary with the image url string and the hemisphere title to a list. \n",
    "This list will contain one dictionary for each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit hemispheres website through splinter module \n",
    "hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(hemispheres_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML Object\n",
    "html_hemi = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "hemi_soup = BeautifulSoup(html_hemi, 'html.parser')\n",
    "\n",
    "# Retreive all items that contain mars hemispheres information\n",
    "items = hemi_soup.find_all('div', class_='item')\n",
    "\n",
    "# Create empty list for hemisphere urls \n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Store the main_ul \n",
    "hemispheres_main_url = 'https://astrogeology.usgs.gov'\n",
    "\n",
    "# Loop through the items previously stored\n",
    "for i in items: \n",
    "    # Store title\n",
    "    title = i.find('h3').text\n",
    "    \n",
    "    # Store link that leads to full image website\n",
    "    partial_img_url = i.find('a', class_='itemLink product-item')['href']\n",
    "    \n",
    "    # Visit the link that contains the full image website \n",
    "    browser.visit(hemispheres_main_url + partial_img_url)\n",
    "    \n",
    "    # HTML Object of individual hemisphere information website \n",
    "    partial_img_html = browser.html\n",
    "    \n",
    "    # Parse HTML with Beautiful Soup for every individual hemisphere information website \n",
    "    soup = BeautifulSoup( partial_img_html, 'html.parser')\n",
    "    \n",
    "    # Retrieve full image source \n",
    "    img_url = hemispheres_main_url + soup.find('img', class_='wide-image')['src']\n",
    "    \n",
    "    # Append the retreived information into a list of dictionaries \n",
    "    hemisphere_image_urls.append({\"title\" : title, \"img_url\" : img_url})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print hemisphere_image_urls\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data into PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Setup connection to mongodb\n",
    "        conn = \"mongodb://localhost:27017\"\n",
    "        client = pymongo.MongoClient(conn)\n",
    "\n",
    "        #Select database and collection to use\n",
    "        db = db.mars\n",
    "        collection = db.mars_info\n",
    "\n",
    "        db.mars_info.insert_many(\n",
    "\n",
    "        [\n",
    "            {'news_title': news_title,\n",
    "            'news_p': news_p, \n",
    "            'featured_image_url': featured_image_url,\n",
    "            'weather_tweet': weather_tweet,\n",
    "            'mars_facts': mars_facts,\n",
    "            'hemisphere_image_urls':hemisphere_image_urls}\n",
    "            ]\n",
    "        )\n",
    "        print(\"Data Uploaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
